Train on 7550 samples, validate on 1803 samples
Epoch 1/1
  80/7550 [..............................] - ETA: 10:03 - loss: 1.3525
 160/7550 [..............................] - ETA: 6:50 - loss: 1.3758
 240/7550 [..............................] - ETA: 5:42 - loss: 1.3762
 320/7550 [>.............................] - ETA: 5:06 - loss: 1.3862
 400/7550 [>.............................] - ETA: 4:44 - loss: 1.3961
 480/7550 [>.............................] - ETA: 4:36 - loss: 1.3811
 560/7550 [=>............................] - ETA: 4:35 - loss: 1.3532
 640/7550 [=>............................] - ETA: 4:26 - loss: 1.3354
 720/7550 [=>............................] - ETA: 4:22 - loss: 1.3675
 800/7550 [==>...........................] - ETA: 4:15 - loss: 1.3811
 880/7550 [==>...........................] - ETA: 4:10 - loss: 1.3804
 960/7550 [==>...........................] - ETA: 4:10 - loss: 1.3774
1040/7550 [===>..........................] - ETA: 4:06 - loss: 1.3535
1120/7550 [===>..........................] - ETA: 4:03 - loss: 1.3469
1200/7550 [===>..........................] - ETA: 3:56 - loss: 1.3439
1280/7550 [====>.........................] - ETA: 3:50 - loss: 1.3435
1360/7550 [====>.........................] - ETA: 3:49 - loss: 1.3459
1440/7550 [====>.........................] - ETA: 3:45 - loss: 1.3596
1520/7550 [=====>........................] - ETA: 3:40 - loss: 1.3645
1600/7550 [=====>........................] - ETA: 3:36 - loss: 1.3689
1680/7550 [=====>........................] - ETA: 3:36 - loss: 1.3598
1760/7550 [=====>........................] - ETA: 3:32 - loss: 1.3827
1840/7550 [======>.......................] - ETA: 3:27 - loss: 1.3830
1920/7550 [======>.......................] - ETA: 3:22 - loss: 1.3752
2000/7550 [======>.......................] - ETA: 3:17 - loss: 1.3840
2080/7550 [=======>......................] - ETA: 3:13 - loss: 1.3774
2160/7550 [=======>......................] - ETA: 3:09 - loss: 1.3738
2240/7550 [=======>......................] - ETA: 3:05 - loss: 1.3785
2320/7550 [========>.....................] - ETA: 3:01 - loss: 1.3732
2400/7550 [========>.....................] - ETA: 2:58 - loss: 1.3634
2480/7550 [========>.....................] - ETA: 2:54 - loss: 1.3653
2560/7550 [=========>....................] - ETA: 2:51 - loss: 1.3632
2640/7550 [=========>....................] - ETA: 2:47 - loss: 1.3651
2720/7550 [=========>....................] - ETA: 2:44 - loss: 1.3629
2800/7550 [==========>...................] - ETA: 2:41 - loss: 1.3677
2880/7550 [==========>...................] - ETA: 2:37 - loss: 1.3629
2960/7550 [==========>...................] - ETA: 2:34 - loss: 1.3637
3040/7550 [===========>..................] - ETA: 2:31 - loss: 1.3638
3120/7550 [===========>..................] - ETA: 2:27 - loss: 1.3617
3200/7550 [===========>..................] - ETA: 2:24 - loss: 1.3619
3280/7550 [============>.................] - ETA: 2:22 - loss: 1.3589
3360/7550 [============>.................] - ETA: 2:18 - loss: 1.3575
3440/7550 [============>.................] - ETA: 2:15 - loss: 1.3566
3520/7550 [============>.................] - ETA: 2:12 - loss: 1.3503
3600/7550 [=============>................] - ETA: 2:09 - loss: 1.3495
3680/7550 [=============>................] - ETA: 2:06 - loss: 1.3500
3760/7550 [=============>................] - ETA: 2:03 - loss: 1.3510
3840/7550 [==============>...............] - ETA: 2:00 - loss: 1.3532
3920/7550 [==============>...............] - ETA: 1:57 - loss: 1.3512
4000/7550 [==============>...............] - ETA: 1:55 - loss: 1.3519
4080/7550 [===============>..............] - ETA: 1:52 - loss: 1.3504
4160/7550 [===============>..............] - ETA: 1:49 - loss: 1.3446
4240/7550 [===============>..............] - ETA: 1:46 - loss: 1.3384
4320/7550 [================>.............] - ETA: 1:44 - loss: 1.3367
4400/7550 [================>.............] - ETA: 1:41 - loss: 1.3389
4480/7550 [================>.............] - ETA: 1:38 - loss: 1.3379
4560/7550 [=================>............] - ETA: 1:35 - loss: 1.3357
4640/7550 [=================>............] - ETA: 1:32 - loss: 1.3303
4720/7550 [=================>............] - ETA: 1:30 - loss: 1.3298
4800/7550 [==================>...........] - ETA: 1:27 - loss: 1.3288
4880/7550 [==================>...........] - ETA: 1:24 - loss: 1.3240
4960/7550 [==================>...........] - ETA: 1:22 - loss: 1.3278
5040/7550 [===================>..........] - ETA: 1:19 - loss: 1.3280
5120/7550 [===================>..........] - ETA: 1:16 - loss: 1.3245
5200/7550 [===================>..........] - ETA: 1:14 - loss: 1.3226
5280/7550 [===================>..........] - ETA: 1:11 - loss: 1.3187
5360/7550 [====================>.........] - ETA: 1:08 - loss: 1.3208
5440/7550 [====================>.........] - ETA: 1:06 - loss: 1.3200
5520/7550 [====================>.........] - ETA: 1:03 - loss: 1.3177
5600/7550 [=====================>........] - ETA: 1:01 - loss: 1.3194
5680/7550 [=====================>........] - ETA: 58s - loss: 1.3227
5760/7550 [=====================>........] - ETA: 55s - loss: 1.3233
5840/7550 [======================>.......] - ETA: 53s - loss: 1.3238
5920/7550 [======================>.......] - ETA: 50s - loss: 1.3256
6000/7550 [======================>.......] - ETA: 48s - loss: 1.3240
6080/7550 [=======================>......] - ETA: 45s - loss: 1.3193
6160/7550 [=======================>......] - ETA: 43s - loss: 1.3188
6240/7550 [=======================>......] - ETA: 40s - loss: 1.3174
6320/7550 [========================>.....] - ETA: 38s - loss: 1.3189
6400/7550 [========================>.....] - ETA: 35s - loss: 1.3191
6480/7550 [========================>.....] - ETA: 33s - loss: 1.3183
6560/7550 [=========================>....] - ETA: 30s - loss: 1.3166
6640/7550 [=========================>....] - ETA: 28s - loss: 1.3165
6720/7550 [=========================>....] - ETA: 25s - loss: 1.3149
6800/7550 [==========================>...] - ETA: 23s - loss: 1.3135
6880/7550 [==========================>...] - ETA: 20s - loss: 1.3129
6960/7550 [==========================>...] - ETA: 18s - loss: 1.3142
7040/7550 [==========================>...] - ETA: 15s - loss: 1.3136
7120/7550 [===========================>..] - ETA: 13s - loss: 1.3121
7200/7550 [===========================>..] - ETA: 10s - loss: 1.3085
7280/7550 [===========================>..] - ETA: 8s - loss: 1.3061
7360/7550 [============================>.] - ETA: 5s - loss: 1.3046
7440/7550 [============================>.] - ETA: 3s - loss: 1.3023
7520/7550 [============================>.] - ETA: 0s - loss: 1.3025
7550/7550 [==============================] - 250s 33ms/step - loss: 1.3041 - val_loss: 0.7723
val MRR 0.339751; val MAP 0.271049
Epoch 00001: map improved from -inf to 0.27105, saving model to model_CuDNNimprovement-01-0.27.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
question_base (InputLayer)      (None, 150)          0
__________________________________________________________________________________________________
answer (InputLayer)             (None, 150)          0
__________________________________________________________________________________________________
bi_lstm (Model)                 (None, 1)            2639729     question_base[0][0]
                                                                 answer[0][0]
==================================================================================================
Total params: 2,639,729
Trainable params: 1,336,129
Non-trainable params: 1,303,600
__________________________________________________________________________________________________

PATH_DATA_TRAIN = 'data/train.txt'
PATH_DATA_DEV = 'data/dev.txt'
PATH_DATA_TEST = 'data/lstm/test_lstm.txt'
PATH_WORD_VECTOR = 'data/lstm/vectors.txt'
PATH_VOCAB = 'data/lstm/vocab_all.txt'
wordvector_dims = 200

qa_embedding = Embedding(
    input_dim=vocab_size + 1,
    input_length=None,
    output_dim=weights.shape[1],
    mask_zero=True,
    weights=[weights])

qa_embedding.trainable = False

bi_lstm1 = Bidirectional(
    LSTM(units=200, return_sequences=False))
bi_lstm2 = Bidirectional(
    LSTM(units=200, return_sequences=False))

training_model.fit(
    [questions_origin, question_related],
    Y,
    epochs=1,
    batch_size=80,
    validation_data=([q_origin_dev_eb, q_related_dev_eb], l_dev),
    verbose=1,
    callbacks=callback_list
)